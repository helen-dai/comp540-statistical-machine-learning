{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from sklearn import linear_model\n",
    "#import sklearn.cross_validation\n",
    "from sklearn import model_selection\n",
    "#from sklearn.cross_validation import KFold\n",
    "import scipy.io\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda = 4.100\n",
      "Coefficients = [-1.62837284] [[-0.01839052 -0.21661119  0.13128384  0.48674888  0.2602243   0.18532733\n",
      "   0.90344911  0.31288822  0.14199547  0.06198638 -0.05335911 -0.15162932\n",
      "  -0.0516569   0.02767041  0.23856918  0.76613529  0.46856035  0.08308522\n",
      "   0.26257561  0.22073129  0.26177729  0.41125323  0.7503693   0.26021176\n",
      "  -1.80207063 -0.62172528 -1.83095331 -0.11174736 -0.67814627 -0.16857307\n",
      "  -0.29711007 -0.20770702 -0.41815432 -0.42931161 -0.34816875  0.32415601\n",
      "   0.010483   -0.14344427 -0.3803836  -0.09968338 -0.63272648 -0.95488787\n",
      "  -0.32285734 -0.7132242  -0.79373552 -1.16416329 -0.133999   -0.67460068\n",
      "  -0.33001795 -0.15734097 -0.11687446  0.22802517  1.48301759  0.49456055\n",
      "  -0.12310253  0.83739199  0.38195683]]\n",
      "Accuracy on set aside test set for std = 0.9219\n",
      "best_lambda = 0.600\n",
      "Coefficients = [-4.60944549] [[-0.45145858 -0.28466487 -0.06327613  0.68295824  1.2105321   0.91505032\n",
      "   2.83046312  1.43678147  0.2414548   0.35775945 -0.3864306  -0.48142892\n",
      "  -0.69586899  0.37456968  0.64885498  1.53956281  1.38118219  0.0719768\n",
      "   0.37642373  0.63502002  0.52274673  0.38563744  2.00138838  1.50817351\n",
      "  -3.14060928 -0.66616926 -4.9064853  -0.03260255 -1.28886337 -0.15745809\n",
      "  -0.63899889 -0.30229395 -1.00990133 -0.42568697 -1.08721767  1.28433248\n",
      "  -0.90558878 -0.35285922 -1.12971447 -0.62589622 -1.40337133 -2.44123542\n",
      "  -1.5565353  -1.94778068 -1.13113805 -2.79991245 -0.75122284 -2.11602215\n",
      "  -1.68510977 -0.66773544 -0.6912564   2.0691305   4.21977655  0.76308888\n",
      "   0.70345799  0.17008517  0.43018827]]\n",
      "Accuracy on set aside test set for logt = 0.9434\n",
      "best_lambda = 1.600\n",
      "Coefficients = [-1.82566817] [[-1.78313887e-01 -1.60085507e-01 -3.73001110e-01  2.36358803e-01\n",
      "   9.46367589e-01  1.59613651e-01  2.03690641e+00  7.62617293e-01\n",
      "   1.81159712e-01  3.12388353e-01 -2.60352275e-01 -4.14115142e-01\n",
      "  -8.66097179e-01  2.36335390e-01  4.75358416e-01  1.43030139e+00\n",
      "   8.23118667e-01 -6.18540136e-02  2.39595774e-01  4.50237962e-01\n",
      "   7.24354332e-01  1.06352180e+00  8.70212070e-01  1.30340906e+00\n",
      "  -2.20348245e+00 -4.57176450e-01 -3.39242058e+00  5.45347539e-01\n",
      "  -5.60588209e-01 -1.85244388e-01 -8.05548612e-01 -4.84223733e-01\n",
      "  -6.36751901e-01 -8.68074827e-02 -6.31860077e-01  3.04485692e-01\n",
      "  -1.03756760e+00  4.18380738e-01 -7.08628404e-01 -2.18361508e-01\n",
      "  -1.07385026e+00 -1.74862153e+00 -6.95533233e-01 -1.43004581e+00\n",
      "  -7.40200632e-01 -2.11078935e+00 -9.46977029e-02 -1.24285032e+00\n",
      "  -2.91376073e-01  1.90460650e-01 -1.65731167e-01  1.19345678e+00\n",
      "   1.42337675e+00  6.04361397e-02  7.86190291e-04  7.86190291e-04\n",
      "   7.86190291e-04]]\n",
      "Accuracy on set aside test set for bin = 0.9284\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda = 4.100\n",
      "Coefficients = [-1.73768364] [[-0.01238104 -0.16453513  0.12353997  0.23877558  0.25044201  0.18016119\n",
      "   0.91021398  0.29051652  0.14338536  0.04950576 -0.02938425 -0.14216649\n",
      "  -0.01129281  0.00969575  0.15854573  0.76286906  0.46477084  0.0679522\n",
      "   0.25630209  0.20397133  0.24507834  0.34909812  0.72719574  0.23138936\n",
      "  -2.41219843 -0.36378637 -3.62007004 -0.01652385 -0.41040368  0.\n",
      "   0.          0.         -0.33464332  0.         -0.06964318  0.258685\n",
      "   0.         -0.11933056 -0.32255484 -0.05034321 -0.27783426 -0.8416277\n",
      "  -0.20211963 -0.59899325 -0.75124044 -1.2267025  -0.09136841 -0.54581205\n",
      "  -0.26427873 -0.13385565 -0.05824876  0.21696855  1.65503721  0.27024338\n",
      "   0.          0.67711581  0.33583451]]\n",
      "Accuracy on set aside test set for std = 0.9225\n",
      "best_lambda = 0.600\n",
      "Coefficients = [-4.75812201] [[ -0.4956468   -0.16215358  -0.04979808   0.48791061   1.24381634\n",
      "    0.91924843   3.02080719   1.46792021   0.22854872   0.40387244\n",
      "   -0.3296986   -0.47273872  -0.6534203    0.34932981   0.10802474\n",
      "    1.52257155   1.5333092    0.           0.39681564   0.49657314\n",
      "    0.50274984   0.44623385   1.97867411   1.37280052  -3.69059054\n",
      "   -0.30270097 -12.44691426   0.          -1.40025659   0.\n",
      "    0.           0.          -0.90435565   0.          -1.04203866\n",
      "    1.36161443  -0.7053245    0.          -1.14262797   0.\n",
      "   -1.78473107  -3.28401682  -2.32227655  -2.46894931  -1.3518189\n",
      "   -3.19168221  -0.24535666  -3.6603592   -1.89709821  -0.6886993\n",
      "    0.           2.06465629   6.09096352   0.38877604   0.74803992\n",
      "    0.12657055   0.48234281]]\n",
      "Accuracy on set aside test set for logt = 0.9453\n",
      "best_lambda = 1.600\n",
      "Coefficients = [-0.39692534] [[-0.09409568 -0.0863297  -0.32438649  0.          0.9656735   0.11782478\n",
      "   2.18781744  0.76531136  0.13854116  0.3143065  -0.20950934 -0.43149486\n",
      "  -0.85151442  0.11337811  0.24253576  1.43546585  0.9269959  -0.00691391\n",
      "   0.17030191  0.39846796  0.68809207  1.08429787  0.79740691  1.38455501\n",
      "  -2.61693176 -0.16466605 -4.66619012  0.41840996 -0.21952198  0.\n",
      "  -0.54555518  0.         -0.54208671  0.         -0.47047139  0.18333451\n",
      "  -1.02387342  0.         -0.6586027   0.         -1.09041829 -2.03840984\n",
      "  -0.54380729 -1.54221925 -0.75832963 -2.38473368  0.         -1.44587275\n",
      "  -0.25649886  0.15504651  0.          1.18315887  1.52604059  0.\n",
      "  -0.71599908 -0.19900597 -0.44613591]]\n",
      "Accuracy on set aside test set for bin = 0.9251\n"
     ]
    }
   ],
   "source": [
    "# No modifications in this cell\n",
    "# complete the functions in utils.py; then run the cell\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,typea,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print(\"best_lambda = %.3f\" %best_lambda)\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True,max_iter=1000)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True,max_iter=1000)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print(\"Coefficients = %s\" %lreg.intercept_,lreg.coef_)\n",
    "    predy = lreg.predict(Xt)\n",
    "    print(\"Accuracy on set aside test set for %s = %.4f\" %(typea, np.mean(predy==ytest)))\n",
    "\n",
    "print(\"L2 Penalty experiments -----------\")\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print(\"L1 Penalty experiments -----------\")\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
